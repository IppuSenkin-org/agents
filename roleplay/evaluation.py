"""
è©•ä¾¡ãƒ»ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯æ©Ÿèƒ½ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
å–¶æ¥­ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è©•ä¾¡ã—ã€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆ
"""
from dataclasses import dataclass, field
from typing import List, Dict
from conversation_flow import ConversationState, ConversationPhase


@dataclass
class SalesPerformanceMetrics:
    """å–¶æ¥­ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹"""

    # åŸºæœ¬æƒ…å ±
    total_turns: int = 0
    final_phase: ConversationPhase = ConversationPhase.SKEPTICAL
    conversation_completed: bool = False

    # ã‚¹ã‚­ãƒ«è©•ä¾¡ï¼ˆ0.0 - 1.0ï¼‰
    objection_handling_score: float = 0.0      # æ‡¸å¿µã¸ã®å¯¾å¿œã‚¹ã‚³ã‚¢
    data_usage_effectiveness: float = 0.0      # å…·ä½“çš„æ•°å­—ã®æ´»ç”¨åº¦
    case_study_relevance: float = 0.0          # äº‹ä¾‹ã®é©åˆ‡æ€§
    rapport_building: float = 0.0              # ä¿¡é ¼æ§‹ç¯‰ã‚¹ã‚­ãƒ«
    listening_skills: float = 0.0              # å‚¾è´åŠ›
    phase_progression_speed: float = 0.0       # ãƒ•ã‚§ãƒ¼ã‚ºé·ç§»é€Ÿåº¦

    # è©³ç´°ãƒ‡ãƒ¼ã‚¿
    concerns_addressed: List[str] = field(default_factory=list)
    data_points_provided: List[str] = field(default_factory=list)
    case_studies_used: List[str] = field(default_factory=list)
    missed_opportunities: List[str] = field(default_factory=list)

    def calculate_overall_score(self) -> float:
        """
        ç·åˆã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—

        Returns:
            float: ç·åˆã‚¹ã‚³ã‚¢ï¼ˆ0.0 - 1.0ï¼‰
        """
        weights = {
            "objection_handling": 0.25,
            "data_usage": 0.25,
            "case_study": 0.15,
            "rapport": 0.15,
            "listening": 0.10,
            "progression": 0.10
        }

        overall = (
            self.objection_handling_score * weights["objection_handling"] +
            self.data_usage_effectiveness * weights["data_usage"] +
            self.case_study_relevance * weights["case_study"] +
            self.rapport_building * weights["rapport"] +
            self.listening_skills * weights["listening"] +
            self.phase_progression_speed * weights["progression"]
        )

        return round(overall, 2)

    def generate_feedback(self) -> str:
        """
        ä¼šè©±çµ‚äº†å¾Œã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ç”Ÿæˆ

        Returns:
            str: ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        """
        overall_score = self.calculate_overall_score()
        feedback_lines = []

        # ãƒ˜ãƒƒãƒ€ãƒ¼
        feedback_lines.append("=" * 60)
        feedback_lines.append("ğŸ“Š å–¶æ¥­ãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤è©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆ")
        feedback_lines.append("=" * 60)
        feedback_lines.append("")

        # ç·åˆè©•ä¾¡
        feedback_lines.append(f"ğŸ¯ ç·åˆã‚¹ã‚³ã‚¢: {overall_score * 100:.0f}/100")
        feedback_lines.append(f"   è©•ä¾¡: {self._get_grade(overall_score)}")
        feedback_lines.append("")

        # åŸºæœ¬æƒ…å ±
        feedback_lines.append(f"ğŸ“ˆ åŸºæœ¬æƒ…å ±:")
        feedback_lines.append(f"   - ç·ã‚¿ãƒ¼ãƒ³æ•°: {self.total_turns}")
        feedback_lines.append(f"   - æœ€çµ‚ãƒ•ã‚§ãƒ¼ã‚º: {self._format_phase(self.final_phase)}")
        feedback_lines.append(f"   - ä¼šè©±å®Œäº†: {'âœ… ã¯ã„' if self.conversation_completed else 'âŒ ã„ã„ãˆ'}")
        feedback_lines.append("")

        # è©³ç´°è©•ä¾¡
        feedback_lines.append("ğŸ“‹ è©³ç´°è©•ä¾¡:")
        feedback_lines.append("")

        # 1. æ‡¸å¿µã¸ã®å¯¾å¿œ
        feedback_lines.append(f"1ï¸âƒ£ æ‡¸å¿µã¸ã®å¯¾å¿œ: {self._format_score(self.objection_handling_score)}")
        if self.objection_handling_score >= 0.8:
            feedback_lines.append("   âœ… ç¤¾é•·ã®æ‡¸å¿µã«å¯¾ã—ã¦å…·ä½“çš„ãªãƒ‡ãƒ¼ã‚¿ã§åŠ¹æœçš„ã«å¯¾å¿œã—ã¾ã—ãŸ")
        elif self.objection_handling_score >= 0.5:
            feedback_lines.append("   âš ï¸  æ‡¸å¿µã¸ã®å¯¾å¿œã¯è‰¯å¥½ã§ã™ãŒã€ã•ã‚‰ã«å…·ä½“ä¾‹ãŒã‚ã‚‹ã¨ã‚ˆã‚Šèª¬å¾—åŠ›ãŒå¢—ã—ã¾ã™")
        else:
            feedback_lines.append("   âŒ ç¤¾é•·ã®æ‡¸å¿µï¼ˆã‚³ã‚¹ãƒˆã€æ™‚é–“ã€åŠ¹æœï¼‰ã¸ã®å¯¾å¿œãŒä¸ååˆ†ã§ã™")

        if self.concerns_addressed:
            feedback_lines.append(f"   å¯¾å¿œã—ãŸæ‡¸å¿µ: {', '.join(self.concerns_addressed)}")
        feedback_lines.append("")

        # 2. å…·ä½“çš„æ•°å­—ã®æ´»ç”¨
        feedback_lines.append(f"2ï¸âƒ£ å…·ä½“çš„æ•°å­—ã®æ´»ç”¨: {self._format_score(self.data_usage_effectiveness)}")
        if self.data_usage_effectiveness >= 0.8:
            feedback_lines.append("   âœ… å…·ä½“çš„ãªæ•°å­—ã‚’åŠ¹æœçš„ã«ä½¿ç”¨ã—ã€èª¬å¾—åŠ›ã®ã‚ã‚‹ææ¡ˆãŒã§ãã¾ã—ãŸ")
        elif self.data_usage_effectiveness >= 0.5:
            feedback_lines.append("   âš ï¸  æ•°å­—ã¯ä½¿ã„ã¾ã—ãŸãŒã€ã‚‚ã†å°‘ã—ROIã‚„åŠ¹æœã‚’å®šé‡çš„ã«ç¤ºã™ã¨è‰¯ã„ã§ã—ã‚‡ã†")
        else:
            feedback_lines.append("   âŒ å…·ä½“çš„ãªæ•°å­—ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚è²»ç”¨ã€åŠ¹æœã€ROIã‚’æ˜ç¢ºã«ç¤ºã—ã¾ã—ã‚‡ã†")

        if self.data_points_provided:
            feedback_lines.append(f"   æä¾›ã—ãŸãƒ‡ãƒ¼ã‚¿: {', '.join(self.data_points_provided)}")
        feedback_lines.append("")

        # 3. äº‹ä¾‹ã®æ´»ç”¨
        feedback_lines.append(f"3ï¸âƒ£ äº‹ä¾‹ã®æ´»ç”¨: {self._format_score(self.case_study_relevance)}")
        if self.case_study_relevance >= 0.8:
            feedback_lines.append("   âœ… é©åˆ‡ãªäº‹ä¾‹ã‚’åŠ¹æœçš„ã«ç´¹ä»‹ã—ã¾ã—ãŸ")
        elif self.case_study_relevance >= 0.5:
            feedback_lines.append("   âš ï¸  äº‹ä¾‹ã¯ç´¹ä»‹ã—ã¾ã—ãŸãŒã€ã‚‚ã†å°‘ã—è©³ã—ãèª¬æ˜ã™ã‚‹ã¨è‰¯ã„ã§ã—ã‚‡ã†")
        else:
            feedback_lines.append("   âŒ å…·ä½“çš„ãªäº‹ä¾‹ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚åŒæ¥­ä»–ç¤¾ã®æˆåŠŸä¾‹ã‚’ç´¹ä»‹ã—ã¾ã—ã‚‡ã†")

        if self.case_studies_used:
            feedback_lines.append(f"   ä½¿ç”¨ã—ãŸäº‹ä¾‹: {', '.join(self.case_studies_used)}")
        feedback_lines.append("")

        # 4. ä¿¡é ¼æ§‹ç¯‰
        feedback_lines.append(f"4ï¸âƒ£ ä¿¡é ¼æ§‹ç¯‰: {self._format_score(self.rapport_building)}")
        if self.rapport_building >= 0.8:
            feedback_lines.append("   âœ… ç¤¾é•·ã¨ã®ä¿¡é ¼é–¢ä¿‚ã‚’åŠ¹æœçš„ã«æ§‹ç¯‰ã—ã¾ã—ãŸ")
        elif self.rapport_building >= 0.5:
            feedback_lines.append("   âš ï¸  ã‚‚ã†å°‘ã—ç¤¾é•·ã®ç«‹å ´ã«å¯„ã‚Šæ·»ã£ãŸææ¡ˆã‚’å¿ƒãŒã‘ã¾ã—ã‚‡ã†")
        else:
            feedback_lines.append("   âŒ ä¿¡é ¼æ§‹ç¯‰ãŒä¸ååˆ†ã§ã™ã€‚ç¤¾é•·ã®æ‡¸å¿µã‚’ç†è§£ã—ã€å¯„ã‚Šæ·»ã†å§¿å‹¢ã‚’ç¤ºã—ã¾ã—ã‚‡ã†")
        feedback_lines.append("")

        # æ”¹å–„ãƒã‚¤ãƒ³ãƒˆ
        if self.missed_opportunities:
            feedback_lines.append("ğŸ’¡ è¦‹é€ƒã—ãŸæ©Ÿä¼š:")
            for opportunity in self.missed_opportunities:
                feedback_lines.append(f"   - {opportunity}")
            feedback_lines.append("")

        # æ¬¡å›ã¸ã®æ¨å¥¨äº‹é …
        feedback_lines.append("ğŸ“ æ¬¡å›ã¸ã®æ¨å¥¨äº‹é …:")
        recommendations = self._generate_recommendations()
        for rec in recommendations:
            feedback_lines.append(f"   {rec}")
        feedback_lines.append("")

        feedback_lines.append("=" * 60)

        return "\n".join(feedback_lines)

    def _get_grade(self, score: float) -> str:
        """ã‚¹ã‚³ã‚¢ã‹ã‚‰è©•ä¾¡ã‚°ãƒ¬ãƒ¼ãƒ‰ã‚’å–å¾—"""
        if score >= 0.9:
            return "S (å„ªç§€)"
        elif score >= 0.8:
            return "A (è‰¯å¥½)"
        elif score >= 0.7:
            return "B (æ™®é€š)"
        elif score >= 0.6:
            return "C (è¦æ”¹å–„)"
        else:
            return "D (ä¸ååˆ†)"

    def _format_score(self, score: float) -> str:
        """ã‚¹ã‚³ã‚¢ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        percentage = score * 100
        bar_length = int(score * 20)
        bar = "â–ˆ" * bar_length + "â–‘" * (20 - bar_length)
        return f"{bar} {percentage:.0f}%"

    def _format_phase(self, phase: ConversationPhase) -> str:
        """ãƒ•ã‚§ãƒ¼ã‚ºã‚’æ—¥æœ¬èªã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        phase_names = {
            ConversationPhase.SKEPTICAL: "æ‡ç–‘çš„",
            ConversationPhase.INTERESTED: "èˆˆå‘³",
            ConversationPhase.CONSIDERING: "æ¤œè¨"
        }
        return phase_names.get(phase, "ä¸æ˜")

    def _generate_recommendations(self) -> List[str]:
        """æ¨å¥¨äº‹é …ã‚’ç”Ÿæˆ"""
        recommendations = []

        if self.objection_handling_score < 0.7:
            recommendations.append(
                "âœ“ ç¤¾é•·ã®æ‡¸å¿µï¼ˆã‚³ã‚¹ãƒˆã€æ™‚é–“ã€åŠ¹æœã€ä¿è¨¼ï¼‰ã‚’äº‹å‰ã«æƒ³å®šã—ã€"
                "å…·ä½“çš„ãªãƒ‡ãƒ¼ã‚¿ã§å¯¾å¿œã™ã‚‹æº–å‚™ã‚’ã—ã¾ã—ã‚‡ã†"
            )

        if self.data_usage_effectiveness < 0.7:
            recommendations.append(
                "âœ“ è²»ç”¨ã€ROIã€åŠ¹æœã‚’å…·ä½“çš„ãªæ•°å­—ã§ç¤ºã—ã¾ã—ã‚‡ã†"
                "ï¼ˆä¾‹: 20ã€œ30ä¸‡å††ã€1.2å€å¢—åŠ ã€å¹´é–“3ä¸‡å††å‰Šæ¸›ï¼‰"
            )

        if self.case_study_relevance < 0.7:
            recommendations.append(
                "âœ“ åŒæ¥­ä»–ç¤¾ã®æˆåŠŸäº‹ä¾‹ã‚’è©³ã—ãç´¹ä»‹ã—ã¾ã—ã‚‡ã†"
                "ï¼ˆç¾¤é¦¬ã®éƒ¨å“ãƒ¡ãƒ¼ã‚«ãƒ¼ã€å®‡éƒ½å®®ã®é‡‘å‹ãƒ¡ãƒ¼ã‚«ãƒ¼ãªã©ï¼‰"
            )

        if self.rapport_building < 0.7:
            recommendations.append(
                "âœ“ ç¤¾é•·ã®ç«‹å ´ã«å¯„ã‚Šæ·»ã„ã€æ‡¸å¿µã‚’ç†è§£ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã—ã‚‡ã†"
            )

        if self.phase_progression_speed < 0.5:
            recommendations.append(
                "âœ“ ä¼šè©±ã®ãƒ†ãƒ³ãƒãŒé…ã™ãã¾ã™ã€‚ç›¸æ‰‹ã®åå¿œã‚’è¦‹ãªãŒã‚‰æƒ…å ±ã‚’æä¾›ã—ã¾ã—ã‚‡ã†"
            )
        elif self.phase_progression_speed > 0.9:
            recommendations.append(
                "âœ“ ä¼šè©±ã®ãƒ†ãƒ³ãƒãŒé€Ÿã™ãã¾ã™ã€‚ç¤¾é•·ãŒç´å¾—ã™ã‚‹ã¾ã§ä¸å¯§ã«èª¬æ˜ã—ã¾ã—ã‚‡ã†"
            )

        if not recommendations:
            recommendations.append("âœ“ ç´ æ™´ã‚‰ã—ã„å–¶æ¥­ã§ã—ãŸï¼ã“ã®èª¿å­ã§é ‘å¼µã£ã¦ãã ã•ã„")

        return recommendations


def evaluate_conversation(state: ConversationState) -> SalesPerformanceMetrics:
    """
    ä¼šè©±çŠ¶æ…‹ã‹ã‚‰å–¶æ¥­ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è©•ä¾¡

    Args:
        state: ä¼šè©±çŠ¶æ…‹

    Returns:
        SalesPerformanceMetrics: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡
    """
    metrics = SalesPerformanceMetrics()

    # åŸºæœ¬æƒ…å ±
    metrics.total_turns = state.turn_count
    metrics.final_phase = state.current_phase
    metrics.conversation_completed = (
        state.current_phase == ConversationPhase.CONSIDERING and
        state.phase_turn_count >= 2
    )

    # æ‡¸å¿µã¸ã®å¯¾å¿œã‚¹ã‚³ã‚¢
    total_concerns = 4  # ã‚³ã‚¹ãƒˆã€æ™‚é–“ã€åŠ¹æœã€ä¿è¨¼
    addressed_concerns = len(state.concerns_raised)
    metrics.objection_handling_score = min(addressed_concerns / total_concerns, 1.0)
    metrics.concerns_addressed = state.concerns_raised

    # å…·ä½“çš„æ•°å­—ã®æ´»ç”¨åº¦
    data_types = ["cost", "roi", "case_study", "time_required", "support_offered"]
    provided_count = sum(1 for dt in data_types if state.data_provided.get(dt, False))
    metrics.data_usage_effectiveness = provided_count / len(data_types)
    metrics.data_points_provided = [
        dt for dt in data_types if state.data_provided.get(dt, False)
    ]

    # äº‹ä¾‹ã®æ´»ç”¨
    case_study_count = len(state.case_studies_mentioned)
    metrics.case_study_relevance = min(case_study_count / 2, 1.0)  # 2ã¤ä»¥ä¸Šã§æº€ç‚¹
    metrics.case_studies_used = state.case_studies_mentioned

    # ä¿¡é ¼æ§‹ç¯‰ï¼ˆãƒ‡ãƒ¼ã‚¿æä¾›ã®è³ªã¨ãƒ•ã‚§ãƒ¼ã‚ºé€²è¡Œåº¦ã‹ã‚‰æ¨å®šï¼‰
    phase_score = {
        ConversationPhase.SKEPTICAL: 0.3,
        ConversationPhase.INTERESTED: 0.6,
        ConversationPhase.CONSIDERING: 1.0
    }
    metrics.rapport_building = phase_score.get(state.current_phase, 0.0)

    # å‚¾è´åŠ›ï¼ˆè³ªå•ã¸ã®å¯¾å¿œçŠ¶æ³ã‹ã‚‰æ¨å®šï¼‰
    metrics.listening_skills = min(len(state.questions_asked) / 5, 1.0)

    # ãƒ•ã‚§ãƒ¼ã‚ºé·ç§»é€Ÿåº¦
    ideal_turns = 12  # ç†æƒ³çš„ãªç·ã‚¿ãƒ¼ãƒ³æ•°ï¼ˆSKEPTICAL 3 + INTERESTED 5 + CONSIDERING 4ï¼‰
    if state.turn_count == 0:
        metrics.phase_progression_speed = 0.0
    else:
        speed = ideal_turns / state.turn_count
        metrics.phase_progression_speed = min(speed, 1.0) if speed <= 1.5 else 0.5

    # è¦‹é€ƒã—ãŸæ©Ÿä¼šã‚’æ¤œå‡º
    if not state.data_provided.get("cost"):
        metrics.missed_opportunities.append("å…·ä½“çš„ãªè²»ç”¨ã‚’æç¤ºã—ã¦ã„ã¾ã›ã‚“")
    if not state.data_provided.get("roi"):
        metrics.missed_opportunities.append("ROIï¼ˆæŠ•è³‡å¯¾åŠ¹æœï¼‰ã‚’ç¤ºã—ã¦ã„ã¾ã›ã‚“")
    if case_study_count == 0:
        metrics.missed_opportunities.append("å…·ä½“çš„ãªäº‹ä¾‹ã‚’ç´¹ä»‹ã—ã¦ã„ã¾ã›ã‚“")
    if not state.data_provided.get("support_offered"):
        metrics.missed_opportunities.append("ã‚µãƒãƒ¼ãƒˆä½“åˆ¶ã‚’èª¬æ˜ã—ã¦ã„ã¾ã›ã‚“")

    return metrics


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆç”¨
    from conversation_flow import ConversationState, ConversationPhase

    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹1: å„ªç§€ãªå–¶æ¥­
    state1 = ConversationState(
        current_phase=ConversationPhase.CONSIDERING,
        turn_count=12,
        phase_turn_count=3
    )
    state1.mark_data_provided("cost")
    state1.mark_data_provided("roi")
    state1.mark_data_provided("case_study")
    state1.mark_data_provided("time_required")
    state1.mark_data_provided("support_offered")
    state1.concerns_raised = ["cost", "time", "effect", "guarantee"]
    state1.case_studies_mentioned = ["gunma_parts", "utsunomiya_mold"]
    state1.questions_asked = ["cost", "roi", "time", "support", "guarantee"]

    metrics1 = evaluate_conversation(state1)
    print(metrics1.generate_feedback())

    print("\n\n" + "=" * 60 + "\n\n")

    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹2: æ”¹å–„ãŒå¿…è¦ãªå–¶æ¥­
    state2 = ConversationState(
        current_phase=ConversationPhase.SKEPTICAL,
        turn_count=3,
        phase_turn_count=3
    )
    state2.mark_data_provided("cost")

    metrics2 = evaluate_conversation(state2)
    print(metrics2.generate_feedback())
